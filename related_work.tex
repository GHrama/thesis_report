\chapter{Related Work}

Participatory social sensing is the active participation of users with their mobile phones to form a network that enables the collection and analyzation of large amounts of data.
The concept was first introduced by Burke et al in 2006, which talks about the potential benefits and propose an initial architecture. Collecting data from various sensors is important for Big data analysis and to find answers to complex social questions. Lei Song et al \cite{song2014health} performed an extensive survey on the sensor devices and their applications. It was found that different sensor combinations is the foundation to grasp important information. Giannotti et al \cite{giannotti2012planetary} propose the \textit{Planetary Nervous System} to collect data from connected sensors and use that data to do big data analysis with privacy awareness.

Some applications of participatory sensing are LiveCompare, TraficSense and CenseMe mobile applications. LiveCompare is introduced by Linda Deng et al
\cite{deng2009livecompare} where the widespread availability of mobile phones is made use of to find cheap groceries making use of the camera for barcode decoding and location to find the stores. TraficSense by Prashanth Mohan et al \cite{mohan2008nericell} is a concept aimed to keep track of traffic on the road with a mixture of traffic and vehicle types. It collects a variety of sensor data such as the accelerometer and the location but not limited to them. CenseMe created by Emiliano Miluzzol et al \cite{miluzzo2007cenceme} where friends in social networks can share their status in terms of their mood, activity, surrounding and habit. This includes physical and virtual sensors that can capture the online life of a person. 

Participatory sensing is needed for a fairer system to trade data due to the fact that many mobile applications take data away from users without their knowledge. Jinyan Zang et al
\cite{zang2015knows} did a study using 110 Android and iOS apps to find the ones that share personal information, behavioural information and location data with third parties. Doing this revealed that it does not require a notification from the application. They also found that paid applications still shared sensitive information to third parties. 

Ashwini Rao et al \cite{rao2015they} examined the behavioural profiles formed by Google and Yahoo. Participants were surprised and concerned that data has been collected from them. Additionally, the profiles formed were found to be in some aspects inaccurate and had excess of information, so much that the profiles did not seem to be anonymous anymore. Further, a survey was created asking participants questions about the behavioural profiles and was launched on Amazon Turk. Participants dint find the profiles formed to be accessible enough and they also complained that they wanted to know more about who and where the data will be used. Overall, the impression of participants is that the whole process of collecting data lacked transparency. This shows that there is a need for more privacy and control of data from the user side.

Studies have been done to investigate the relationship of users and their data. Alesaandro Acquisti et al \cite{acquisti2005privacy} created a survey to observe the privacy concerns in e-commerce preferences and masking of location data. They found that users do not make reckless decisions, rather they make decisions based on what information they have, how much they care and what they believe the effect of their actions will be. This leans on the fact that with sufficient information users can make rational choices about the privacy of their data. 

Rebecca Balebacco et al \cite{balebako2015impact} study through surveys and an experiment that users do not remember the sensors accessed by each application, shown during installation of the mobile application and proposes to inform users during the use of the application itself before collecting the sensor data. Similarly, Lin Jialiu et al \cite{lin2012expectation} examines through crowdsourcing the perception of users to the data collection from mobile applications. The main takeaway from here is that users felt more comfortable if the purpose of a resource access was stated.

Additionally, studies have been done on assessing sensor data sharing in mobile phones. George Danezis et al \cite{danezis2005much} did a study to assess how much people value their location data using auction technique. They found that the median bid was 43\$ a period of one month, but this varied a lot on whether the person was a student, the relationship status and their travelling habits.  Dan Cvreck et al \cite{cvrcek2006study} also examines the value of location privacy with over 1200 people and varied demographics. In this case the users were told fake goals in order not to be biased about their data privacy. Contradictions were found to the study \cite{danezis2005much} about the change in value due to travelling habits, but the median bid was found to be the same. There was also differences in results among the uses with different demographics. This goes to show that one incentive does not fit all the users.

Delphine Christine et al \cite{christin2013s} perform an extention of the study in the paper by George Danezis et al \cite{danezis2005much}. It is attempted to analyse how various factors can affect data sharing such as demographics, incentives and spatio-temporal elements vary the importance users have on their data for various sensors. Other aspects such as the purpose for which data is shared and to whom the data is shared is also studied. It is found that younger people and people with affiliations with buyers of their data tend to share more information. They also found that users claimed more rewards to corporations. The work by Camp Jean \cite{camp2005state} has mentioned that the participants of the surveys may not tell the truth inspite of financial rewards. The later only ensures that the users successfully complete the survey.

Other than the surveys, there are studies done on the mobile phones themselves. Brush et al \cite{brush2010exploring} collect the location data of 32 users for a period of 2 months. Users have five privacy options they can choose from:

\begin{itemize}
\item Deleting near home
\item Mixing to provide k anonymity
\item Randomizing
\item Discretizing
\item Subsampling
\end{itemize}

At the end of the two months, users were shown visualizations of their data. The authors mentioned that the user interface was not intuitive and that users might have been biased to the location data due to the experimental setup. Additionally, it was found that users were not consistent with privacy decisions and with whom they shared data. It was concluded that users need to be properly informed about every detail to enable them to make rational choices.

Haksoo Choi et al \cite{choi2011sensorsafe} is a framework that provides sharing of sensor data based on rules along with the possibility of applying obfuscation algorithms. They found that users share data with a purpose and hence the purpose of data sharing should be included in the rules. Additionally, Eiji Hayashi et al \cite{hayashi2012goldilocks} with 20 participants examine the sensor data sharing with all or nothing options. It is found that all or nothing options are a poor fit for user preferences and sharing of partial sensor information should also be provided.

Various algorithms can be used to protect the privacy of users while providing various amounts of data sharing possibilities. Pournaras et al \cite{pournaras2016self} propose a scheme where users have the possibility to share various amounts of data. Users supply data to the data aggregators who buy data. The incentives that are received depend on the accuracy of the data that is shared and the accuracy required by the data aggregators. If the data shared is of lower accuracy then the errors in data processing increase. Similarly, with higher accuracy the data processing tasks will give lesser errors. The process of manipulating the accuracy of sensor data is called summarization. The errors in the data has the possibility to be mitigated if there is a large population of users participating in the data sharing tasks. Summarization is any algorithm from simple arithmetic functions to clustering algorithms.

In this dissertation, it is attempted to address some of the drawbacks of the aforementioned studies. A social experiment is created and an Android application developed to study the relationship between incentives and data sharing for a wide range of sensors.
Additional factors that can affect data sharing are also included in the equation such as potential data buyers and the purpose for which the data collected is used. Users are allowed to share data in five levels each corresponding to a summarization level. 

The user interface has been designed to be intuitive and easy to use. Users are approached to share their data and are incentivized with some credits. The amount of credit received is proportional to the amount of data shared. The amount of credit per data request is dynamically allocated according to the user profile created. High amounts are allocated to data requests that are considered privacy intrusive by the user. To keep the users motivated a participation fee is included, which means users will receive credits for answering questions irrespective of the amount of data shared.
Additionally, a survey is deployed before the experiment to gain insight into the perception of users on various features and to fine tune the mobile application details.

Delphine Christine et al \cite{christin2016privacy} conclude their paper on the challenges for the future, the following points have been addressed \cite{pournarasethical}:

\begin{itemize}
\item Including the participants in the privacy equation
\item Providing composable privacy solutions
\item Trade-offs between privacy, performance and data fidelity
\item Making privacy measurable
\item Defining standards for privacy research
\item Holistic architecture blueprints
\end{itemize}



