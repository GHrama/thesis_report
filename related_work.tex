\chapter{Related Work}

Participatory social sensing is the active participation of users with their mobile phones and any other sensory devices to form a network that enables the collection and analysis of data. The ubiquity of mobile devices and cellular infrastructure makes it a possibility to obtain data over a large area with minimal incremental cost. Burke et al talk about the concept \cite{burke2006participatory} and further highlight the potential benefits and propose an architecture. Collecting data from various sensors is important for Big Data analysis and to find answers to complex social questions such as sentiment evolution and the spread of epidemics \cite{giannotti2012planetary}. Lei Song et al \cite{song2014health} performs an extensive survey on the sensory devices for the purpose of health sensing and finds that different sensor combinations is the pillar to obtaining meaningful signals. Giannotti et al \cite{giannotti2012planetary} propose the \textit{Planetary Nervous System} to collect data from connected sensors and use that data to do big data analysis with privacy awareness.

Some applications of participatory sensing are LiveCompare, TraficSense and CenseMe mobile applications. LiveCompare is introduced by Linda Deng et al
\cite{deng2009livecompare} where the widespread availability of mobile phones is made use of to find cheap groceries making use of the camera for barcode decoding and location to find the stores. TraficSense by Prashanth Mohan et al \cite{mohan2008nericell} is a concept aimed to keep track of traffic on the road with a mixture of traffic and vehicle types. It collects a variety of sensor data such as the accelerometer and the location but not limited to them. CenseMe created by Emiliano Miluzzol et al \cite{miluzzo2007cenceme} where friends in social networks can share their status in terms of their mood, activity, surrounding and habit. This includes physical and virtual sensors that can capture the online life of a person. 

Participatory sensing is needed for a fairer system to trade data due to the fact that many mobile applications take data away from users without their knowledge. Jinyan Zang et al
\cite{zang2015knows} does a study using 110 Android and iOS apps to find the ones that share personal information, behavioural information and location data with third parties. This also reveals that collecting user information does not require a notification from the application. They also find that paid applications still share sensitive information to third parties. 

Ashwini Rao et al \cite{rao2015they} examine the behavioural profiles formed by Google and Yahoo. Participants are surprised and concerned that data is collected from them. Additionally, the profiles formed are found to be in some aspects inaccurate and have excess information, that the profiles did not seem to be anonymous anymore. Further, a survey is created asking participants questions about the behavioural profiles and is launched on Amazon Turk. Participants find the profiles formed to be not easily accessible and also complained that they wanted to know more about who is going to use their data and what it is used for. Overall, the impression of participants is that the whole process of collecting data lacked transparency. This shows that there is a need for more privacy and control of data from the user side.

Studies have been to investigate the relationship of users and their data. Alesaandro Acquisti et al \cite{acquisti2005privacy} create a survey to observe the privacy concerns in e-commerce preferences and masking of location data. They find that users do not make reckless decisions, rather they make decisions based on what information they have, how much they care and what they believe the effect of their actions are. This leans on the fact that with sufficient information, users can make rational choices about the privacy of their data. 

Rebecca Balebacco et al \cite{balebako2015impact} study through surveys and an experiment that users do not remember the sensors accessed by each application, shown during installation of the mobile application and proposes to inform users during the use of the application itself before collecting the sensor data. Similarly, Lin Jialiu et al \cite{lin2012expectation} examines through crowdsourcing the perception of users to the data collection from mobile applications. The main takeaway from here is that users feel more comfortable if the purpose of a resource access is stated.

Additionally, studies have been done on assessing sensor data sharing in mobile phones. George Danezis et al \cite{danezis2005much} does a study to assess how much people value their location data using auction technique. They find that the median bid is 43 Euros for a period of one month, but this varies a lot on whether the person is a student, the relationship status and their travelling habits.  Dan Cvreck et al \cite{cvrcek2006study} also examines the value of location privacy with over 1200 people and varied demographics. In this case the users are told fake goals in order not to be biased about their data privacy. Contradictions are found against the study \cite{danezis2005much} about the change in value due to travelling habits, but the median bid is found to be the same. There are also differences in results among the uses with different demographics. This shows that one incentive does not fit all users.

Delphine Christine et al \cite{christin2013s} perform an extention of the study in the paper of George Danezis et al \cite{danezis2005much}. It is attempted to analyse how various factors can affect data sharing such as demographics, incentives and spatio-temporal elements vary the importance users have on their data for various sensors. Other aspects such as the purpose for which data is shared and to whom the data is shared is also studied. It is found that younger people and people with affiliations with buyers of their data tend to share more information. They also find that users claim more rewards to corporations. The work by Camp Jean \cite{camp2005state} mentions that the participants of surveys may not tell the truth despite financial rewards. The later only ensures that the users successfully complete the survey.

Other than the surveys, there are studies done on the mobile phones themselves. Brush et al \cite{brush2010exploring} collect the location data of 32 users for a period of 2 months. Users have five privacy options they can choose from:

\begin{itemize}
\item Deleting near home
\item Mixing to provide k anonymity
\item Randomizing
\item Discretizing
\item Subsampling
\end{itemize}

At the end of the two months, users are shown visualizations of their data. The authors mention that the user interface is not intuitive and that users might be biased to the location data due to the experimental setup. Additionally, it is found that users are not consistent with privacy decisions and with whom they share data. It is concluded that users need to be properly informed about every detail to enable them to make rational choices.

Haksoo Choi et al \cite{choi2011sensorsafe} propose a framework that provides sharing of sensor data based on rules along with the possibility of applying obfuscation algorithms. They find that users share data with a purpose and hence the purpose of data sharing should be included in the rules. Additionally, Eiji Hayashi et al \cite{hayashi2012goldilocks} with 20 participants examine the sensor data sharing with all or no options. It is found that all or no options are a poor fit for user preferences and sharing of partial sensor information should also be provided.

Various algorithms can be used to protect the privacy of users while providing various amounts of data sharing possibilities. Pournaras et al \cite{pournaras2016self} propose a scheme where users have the possibility to share various amounts of data. Users supply data to the data aggregators who buy data. The incentives that are received depend on the quality of the data that is shared and the quality required by the data aggregators. If the data shared is of lower quality then the errors in data processing increase. Similarly, with higher quality the data processing tasks give lesser errors. The process of manipulating the quality of sensor data is called summarization. The errors in the data have the possibility to be mitigated if there is a large population of users participating in the data sharing tasks. Summarization concerns algorithms from simple arithmetic functions to clustering algorithms.

Delphine Christine et al \cite{christin2016privacy} conclude their paper on the challenges for the future, the following points have been addressed \cite{pournarasethical}:

\begin{itemize}
\item Including the participants in the privacy equation
\item Providing composable privacy solutions
\item Trade-offs between privacy, performance and data fidelity
\item Making privacy measurable
\item Defining standards for privacy research
\item Holistic architecture blueprints
\end{itemize}

Below is a collection of the drawbacks from the above mentioned papers:
\begin{itemize}
\item \textbf{No transparency in data collection} - Users are not informed about the process, time and duration of data collection.
\item \textbf{Poor data accessibility} -  Users do not have easy access to the data collected from them
\item \textbf{Need for more information about data collection} - Users are not informed about what data is being collected, who is collecting their data and the purpose of collection
\item \textbf{Users lack control over their data} - Users lack the possibility to share or not share their data. Furthermore they cannot decide on the privacy(quality) of data to share
\item \textbf{No personalized incentives} - Incentives to data requests are not tailored to the user profile
\end{itemize}

Users need a platform where they have control over the sharing of their data. Furthermore, they should be informed about the process of data collection in a transparent manner by being given all the information needed to make a decision, whether to share their data or not. This includes the duration and time of data collection. Additionally, users should have the option to choose the privacy (quality) of their data to share instead of being restricted to all or no options. Users should know who is collecting their data, what data is being collected and for what purpose this data is used. Users should also have easy accessibility to see the data collected from them.


